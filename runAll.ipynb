{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyMsA1okzwiXrIsWVAWKrfDG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3UsIGBFnLnJ_"},"outputs":[],"source":["source_videos_path = \"/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos\"\n","destination_videos_path = \"/content/drive/MyDrive/NLP_Project/cropped_outputs\"\n","input_video_for_tarncribe = \"input.mp4\"\n","subtitle_language = 'tr'  # Turkish language code\n","maxlen = 79\n","num_classes = 7\n","\n","\n","softmax_of_text = '/content/drive/MyDrive/NLP_Project/softmax_output_of_text.txt'\n","softmax_of_video = '/content/drive/MyDrive/NLP_Project/softmax_output_of_video.txt'\n","\n","video_path = destination_videos_path + \"/\" + input_video_for_tarncribe\n","output_folder = \"/content/drive/MyDrive/NLP_Project/Photos_to_predict\"\n","\n","\n","input_video_to_add_sentiment = \"/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos/output-translated.mp4\"  # Get the uploaded video filename\n","output_video_with_audio = \"Final_Video.mp4\"\n"]},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"8e7rHBhsS_NZ","executionInfo":{"status":"error","timestamp":1716413042783,"user_tz":-180,"elapsed":11238,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"199ad218-3654-4bc5-8a17-805de35251d2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOrBFFRJLWO-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716373794264,"user_tz":-180,"elapsed":303,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"dd0781f3-b93d-498b-cb50-402d5add4c8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN\n"]}],"source":["%cd /content/drive/MyDrive/NLP_Project/testMarlin/MARLIN"]},{"cell_type":"code","source":["!pip install ffmpeg\n","!pip install marlin_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"58kdq9fnsfJr","executionInfo":{"status":"ok","timestamp":1716373864453,"user_tz":-180,"elapsed":69887,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"f2295239-147f-46c0-ba74-8fbeaea280df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=0b94e859e102ea71cc8d543f7f1c7c4acd21043f08fb1391b1bac7fcbddfbbd3\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n","Collecting marlin_pytorch\n","  Downloading marlin_pytorch-0.3.4-py3-none-any.whl (25 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (0.18.0+cu121)\n","Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (1.25.2)\n","Collecting einops>=0.1 (from marlin_pytorch)\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpeg-python>=0.2.0 (from marlin_pytorch)\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: opencv-python>=4.3 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (4.8.0.76)\n","Collecting av>=6.0 (from marlin_pytorch)\n","  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (4.66.4)\n","Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.10/dist-packages (from marlin_pytorch) (6.0.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->marlin_pytorch) (0.18.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->marlin_pytorch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->marlin_pytorch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->marlin_pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->marlin_pytorch) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->marlin_pytorch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->marlin_pytorch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, einops, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, marlin_pytorch\n","Successfully installed av-12.0.0 einops-0.8.0 ffmpeg-python-0.2.0 marlin_pytorch-0.3.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["import glob\n","import logging.config\n","import os\n","import sys\n","from concurrent.futures import ProcessPoolExecutor\n","from pathlib import Path\n","from typing import Tuple\n","\n","import cv2\n","import ffmpeg\n","import yaml\n","from numpy import ndarray\n","from tqdm.auto import tqdm\n","\n","\n","\n","from marlin_pytorch.util import crop_with_padding\n","from util.face_sdk.core.model_loader.face_detection.FaceDetModelLoader import FaceDetModelLoader\n","from util.face_sdk.core.model_handler.face_detection.FaceDetModelHandler import FaceDetModelHandler"],"metadata":{"id":"UvLLhdrrsNj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logging.config.fileConfig(os.path.join(\"util\", \"face_sdk\", \"config\", \"logging.conf\"))\n","logger = logging.getLogger('api')\n","\n","with open(os.path.join(\"util\", \"face_sdk\", \"config\", \"model_conf.yaml\")) as f:\n","    model_conf = yaml.load(f, Loader=yaml.FullLoader)\n","\n","# common setting for all model, need not modify.\n","model_path = os.path.join(\"util\", \"face_sdk\", 'models')\n","\n","# model setting, modified along with model\n","scene = 'non-mask'\n","model_category = 'face_detection'\n","model_name = model_conf[scene][model_category]"],"metadata":{"id":"OuT3ku_JsNin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger.info('Start to load the face detection model...')\n","# load model\n","sys.path.append(os.path.join(\"util\", \"face_sdk\"))\n","faceDetModelLoader = FaceDetModelLoader(model_path, model_category, model_name)\n","model, cfg = faceDetModelLoader.load_model()\n","faceDetModelHandler = FaceDetModelHandler(model, 'cuda:0', cfg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_-Y1dqRsNf5","executionInfo":{"status":"ok","timestamp":1716373885432,"user_tz":-180,"elapsed":5363,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"905cad4e-f69a-42e4-b75a-ae89164a7665"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 2024-05-22 10:31:19 <ipython-input-6-87c6f92a1489>: 1] Start to load the face detection model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.RetinaFace' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torchvision.models._utils.IntermediateLayerGetter' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.FPN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.SSH' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.ClassHead' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.BboxHead' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.10/dist-packages/torch/serialization.py:1113: SourceChangeWarning: source code of class 'models.network_def.retinaface_def.LandmarkHead' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n"]}]},{"cell_type":"code","source":["def crop_face(frame, margin=1, x=0, y=0) -> Tuple[ndarray, int, int, int]:\n","    assert frame.ndim == 3 and frame.shape[2] == 3, \"frame should be 3-dim\"\n","    dets = faceDetModelHandler.inference_on_image(frame)\n","    if len(dets) > 0:\n","        x1, y1, x2, y2, confidence = dets[0]\n","        # center\n","        x, y = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n","        margin = int(max(abs(x2 - x1), abs(y2 - y1)) / 2)\n","    # crop face\n","    face = crop_with_padding(frame, x - margin, x + margin, y - margin, y + margin, 0)\n","    face = cv2.resize(face, (224, 224))\n","    return face, margin, x, y\n"],"metadata":{"id":"WsZZzRyssNc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_face_video(video_path: str, save_path: str, fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=30) -> None:\n","    cap = cv2.VideoCapture(video_path)\n","    writer = cv2.VideoWriter(save_path, fourcc=fourcc, fps=fps, frameSize=(224, 224))\n","    x, y = 0, 0\n","    margin = 1\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if ret:\n","            face, margin, x, y = crop_face(frame, margin, x, y)\n","            writer.write(face)\n","        else:\n","            break\n","\n","    cap.release()\n","    writer.release()\n"],"metadata":{"id":"4LeZp0gmsNZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_face_img(img_path: str, save_path: str):\n","    frame = cv2.imread(img_path)\n","    face = crop_face(frame)[0]\n","    cv2.imwrite(save_path, face)\n"],"metadata":{"id":"ccYiwRCZt7K8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_videos(video_path, output_path, ext=\"mp4\", max_workers=8):\n","    if ext == \"mp4\":\n","        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","    elif ext == \"avi\":\n","        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n","    else:\n","        raise ValueError(\"ext should be mp4 or avi\")\n","\n","    Path(output_path).mkdir(parents=True, exist_ok=True)\n","\n","    files = os.listdir(video_path)\n","    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n","        futures = []\n","\n","        for f_name in tqdm(files):\n","            if f_name.endswith('.' + ext):\n","                source_path = os.path.join(video_path, f_name)\n","                target_path = os.path.join(output_path, f_name)\n","                fps = eval(ffmpeg.probe(source_path)[\"streams\"][0][\"avg_frame_rate\"])\n","                futures.append(executor.submit(crop_face_video, source_path, target_path, fourcc,\n","                    fps))\n","\n","        for future in tqdm(futures):\n","            future.result()\n"],"metadata":{"id":"XGkdI3y5t7IR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def process_images(image_path: str, output_path: str, max_workers: int = 8):\n","    Path(output_path).mkdir(parents=True, exist_ok=True)\n","    files = glob.glob(f\"{image_path}/*/*/*.jpg\")\n","    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n","        futures = []\n","\n","        for file in tqdm(files):\n","            save_path = file.replace(image_path, output_path)\n","            Path(\"/\".join(save_path.split(\"/\")[:-1])).mkdir(parents=True, exist_ok=True)\n","            futures.append(executor.submit(crop_face_img, file, save_path))\n","\n","        for future in tqdm(futures):\n","            future.result()\n"],"metadata":{"id":"Ri8YsJXqt7FA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["process_videos(source_videos_path, destination_videos_path, ext=\"mp4\")"],"metadata":{"id":"35PbLgjOMQSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gs9iD5k3MQKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e_20u4WvNa22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hsuddlF_OSoi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Iy1MBCp3OSld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nn7tQFucUcU7","executionInfo":{"status":"ok","timestamp":1716385039626,"user_tz":-180,"elapsed":10,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"77a0777e-6dad-47cb-ae15-2167c5a73d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ACcrOZHQhl__","executionInfo":{"status":"ok","timestamp":1716385044379,"user_tz":-180,"elapsed":4760,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"a6693f0a-f0e2-442a-a4a4-fdabc98707d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.2)\n","Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: av<13,>=11.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (12.0.0)\n","Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.3.0)\n","Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.0)\n","Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n","Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.18.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n","Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.11.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n"]}],"source":["!pip3 install faster-whisper ffmpeg-python"]},{"cell_type":"code","source":["!pip3 freeze > /content/requirements.txt"],"metadata":{"id":"gR3DWTzVhyaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import math\n","import ffmpeg\n","\n","from faster_whisper import WhisperModel\n","\n","model = WhisperModel(\"large\")\n","\n"],"metadata":{"id":"-x2YW1rEiI0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_video = input_video_for_tarncribe\n","input_video_name = input_video.replace(\".mp4\", \"\")"],"metadata":{"id":"YtHye9dxUUJd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_audio(input_video, input_video_name):\n","    extracted_audio = f\"audio-{input_video_name}.wav\"\n","    stream = ffmpeg.input(input_video)\n","    stream = ffmpeg.output(stream, extracted_audio)\n","    ffmpeg.run(stream, overwrite_output=True)\n","    return extracted_audio"],"metadata":{"id":"LDQ7lj1HiMoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extracted_audio = extract_audio(input_video, input_video_name)"],"metadata":{"id":"60WO4Cu_iU5g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transcribe(audio):\n","    segments, info = model.transcribe(audio)\n","    language = info[0]\n","    print(\"Transcription language\", info[0])\n","    segments = list(segments)\n","    for segment in segments:\n","        # print(segment)\n","        print(\"[%.2fs -> %.2fs] %s\" %\n","              (segment.start, segment.end, segment.text))\n","    return language, segments"],"metadata":{"id":"tw6mo9_IiX5x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["language, segments = transcribe(audio=extracted_audio)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QM52MesolWBN","executionInfo":{"status":"ok","timestamp":1716385049368,"user_tz":-180,"elapsed":1403,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"59856331-1ded-4583-d276-f47ea9692a0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcription language en\n","[0.00s -> 2.00s]  Hey, this is Ken from AES.\n","[2.00s -> 6.00s]  Sometimes we're asked about the difference between what we do and a textbook.\n","[6.00s -> 8.00s]  Let's talk about textbooks first.\n","[8.00s -> 13.00s]  The best thing about a textbook is you can buy it once and you can keep using it for three or four years.\n"]}]},{"cell_type":"code","source":["def format_time(seconds):\n","\n","    hours = math.floor(seconds / 3600)\n","    seconds %= 3600\n","    minutes = math.floor(seconds / 60)\n","    seconds %= 60\n","    milliseconds = round((seconds - math.floor(seconds)) * 1000)\n","    seconds = math.floor(seconds)\n","    formatted_time = f\"{hours:02d}:{minutes:02d}:{seconds:01d},{milliseconds:03d}\"\n","\n","    return formatted_time"],"metadata":{"id":"hnTFVlaJmt2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_subtitle_file(language, segments):\n","\n","    subtitle_file = f\"sub.srt\"\n","    text = \"\"\n","    for index, segment in enumerate(segments):\n","        segment_start = format_time(segment.start)\n","        segment_end = format_time(segment.end)\n","        text += f\"{str(index+1)} \\n\"\n","        text += f\"{segment_start} --> {segment_end} \\n\"\n","        text += f\"{segment.text} \\n\"\n","        text += \"\\n\"\n","\n","    f = open(subtitle_file, \"w\")\n","    f.write(text)\n","    f.close()\n","\n","    return subtitle_file"],"metadata":{"id":"Qq6Caip4vFkz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_subtitle_to_video(soft_subtitle, subtitle_file,  subtitle_language, input_video, input_video_name):\n","\n","    video_input_stream = ffmpeg.input(input_video)\n","    subtitle_input_stream = ffmpeg.input(subtitle_file)\n","    output_video = f\"output-translated.mp4\"\n","    subtitle_track_title = subtitle_file.replace(\".srt\", \"\")\n","\n","    if soft_subtitle:\n","        stream = ffmpeg.output(\n","            video_input_stream, subtitle_input_stream, output_video, **{\"c\": \"copy\", \"c:s\": \"mov_text\"},\n","            **{\"metadata:s:s:0\": f\"language={subtitle_language}\",\n","            \"metadata:s:s:0\": f\"title={subtitle_track_title}\"}\n","        )\n","        ffmpeg.run(stream, overwrite_output=True)\n","    else:\n","        stream = ffmpeg.output(video_input_stream, output_video,\n","                                vf=f\"subtitles={subtitle_file}\")\n","        ffmpeg.run(stream, overwrite_output=True)"],"metadata":{"id":"qvF568AfvQem"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install required libraries\n","!pip install googletrans==3.1.0a0\n"],"metadata":{"id":"2KeifTgqvoFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716385057442,"user_tz":-180,"elapsed":4608,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"c8e3a82f-08c8-4bf3-fd93-1007d7cb5666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n","Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.2.2)\n","Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.5.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n","Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n","Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n","Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n","Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n","Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n","Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n","Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"]}]},{"cell_type":"code","source":["segments, info = model.transcribe(extracted_audio)\n"],"metadata":{"id":"ITvf3AKzOid9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = []\n","sentences_num = 0\n","for segment in segments:\n","  text.append(segment.text)\n","  sentences_num += 1\n"],"metadata":{"id":"6dBWyyEpO1Td"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93leiV1-PgID","executionInfo":{"status":"ok","timestamp":1716385058671,"user_tz":-180,"elapsed":38,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"5a1879d3-f112-4597-b806-c0427e210b62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' Hey, this is Ken from AES.',\n"," \" Sometimes we're asked about the difference between what we do and a textbook.\",\n"," \" Let's talk about textbooks first.\",\n"," ' The best thing about a textbook is you can buy it once and you can keep using it for three or four years.']"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgaUqPx_fuOl","executionInfo":{"status":"ok","timestamp":1716385058671,"user_tz":-180,"elapsed":34,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"2939a216-fff3-4cf8-aec0-a72f7e03e5e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["# Open the file for writing\n","with open(\"sentences.txt\", \"w\") as text_file:\n","  # Loop through each element in the array\n","  for line in text:\n","    print(line)\n","    # Write the line to the file with a newline character at the end\n","    text_file.write(line + \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zolEyk92frWI","executionInfo":{"status":"ok","timestamp":1716385058671,"user_tz":-180,"elapsed":29,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"9c517531-ba12-4ee2-9d73-d28a65433b21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Hey, this is Ken from AES.\n"," Sometimes we're asked about the difference between what we do and a textbook.\n"," Let's talk about textbooks first.\n"," The best thing about a textbook is you can buy it once and you can keep using it for three or four years.\n"]}]},{"cell_type":"code","source":["from googletrans import Translator\n","\n","\n","\n","\n","# Initialize translator\n","translator = Translator()\n","# Define translation language (replace 'fr' with your desired language code)\n","target_language = 'tr'\n","\n","# Translate the text\n","translated = translator.translate(text, dest=target_language)\n","translated[0].text\n"],"metadata":{"id":"ddz3BzMNQ3Z2","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1716385058672,"user_tz":-180,"elapsed":26,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"1dc507a1-6185-4b67-d662-f64d6800de4d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Merhaba, bu AES'ten Ken.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["translated_text = [element.text for element  in translated]\n","translated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPWJf5GrfWE_","executionInfo":{"status":"ok","timestamp":1716385058672,"user_tz":-180,"elapsed":25,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"425e29c3-b49b-4012-a51e-dd63108a2b88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"Merhaba, bu AES'ten Ken.\",\n"," 'Bazen bize yaptıklarımız ile bir ders kitabı arasındaki fark sorulur.',\n"," 'Önce ders kitaplarından bahsedelim.',\n"," 'Bir ders kitabının en iyi yanı, onu bir kere satın alıp üç ya da dört yıl boyunca kullanmaya devam edebilmenizdir.']"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["\n","\n","\n","# Print the translated text\n","print(f\"Original Text: {text}\")\n","print(f\"Translated Text ({target_language}): {translated_text}\")"],"metadata":{"id":"JD4j6gQ3UcPZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716385058672,"user_tz":-180,"elapsed":20,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"5a47c822-132b-4acf-a40d-6701532e6eb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text: [' Hey, this is Ken from AES.', \" Sometimes we're asked about the difference between what we do and a textbook.\", \" Let's talk about textbooks first.\", ' The best thing about a textbook is you can buy it once and you can keep using it for three or four years.']\n","Translated Text (tr): [\"Merhaba, bu AES'ten Ken.\", 'Bazen bize yaptıklarımız ile bir ders kitabı arasındaki fark sorulur.', 'Önce ders kitaplarından bahsedelim.', 'Bir ders kitabının en iyi yanı, onu bir kere satın alıp üç ya da dört yıl boyunca kullanmaya devam edebilmenizdir.']\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44h9rcodh0Dt","executionInfo":{"status":"ok","timestamp":1716385173459,"user_tz":-180,"elapsed":524,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"f868e0a2-121a-4df6-bbab-f04926194769"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos\n"]}]},{"cell_type":"code","source":["import ffmpeg\n","from googletrans import Translator\n","\n","def add_subtitle_to_video(soft_subtitle, subtitle_file, subtitle_language, input_video, input_video_name):\n","    video_input_stream = ffmpeg.input(input_video)\n","    subtitle_input_stream = ffmpeg.input(subtitle_file)\n","    output_video = f\"output-{input_video_name}.mp4\"\n","    subtitle_track_title = subtitle_file.replace(\".srt\", \"\")\n","\n","    if soft_subtitle:\n","        stream = ffmpeg.output(\n","            video_input_stream, subtitle_input_stream, output_video, **{\"c\": \"copy\", \"c:s\": \"mov_text\"},\n","            **{\"metadata:s:s:0\": f\"language={subtitle_language}\",\n","               \"metadata:s:s:0\": f\"title={subtitle_track_title}\"}\n","        )\n","        ffmpeg.run(stream, overwrite_output=True)\n","    else:\n","        stream = ffmpeg.output(video_input_stream, output_video,\n","                               vf=f\"subtitles={subtitle_file}\")\n","        ffmpeg.run(stream, overwrite_output=True)"],"metadata":{"id":"cHsx-s2fhenc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Initialize translator\n","translator = Translator()\n","target_language = 'tr'\n","\n","# Read the subtitle file\n","with open('/content/drive/MyDrive/NLP_Project/testMarlin/MARLIN/test/videos/sub.srt', 'r', encoding='utf-8') as file:\n","    lines = file.readlines()\n"],"metadata":{"id":"XgrMGbEbhkhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","translated_lines = []\n","text_block = \"\"\n","time_block = \"\"\n"],"metadata":{"id":"dASqmythhme_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","for line in lines:\n","    if '-->' in line:\n","        if text_block:\n","            translated = translator.translate(text_block.strip(), dest=target_language).text\n","            translated_lines.append(text_block.strip())\n","            translated_lines.append(translated + \"\\n\")\n","        text_block = \"\"\n","        time_block = line.strip()\n","        translated_lines.append(time_block)\n","    elif line.strip().isdigit():\n","        translated_lines.append(line.strip())\n","    else:\n","        text_block += line\n"],"metadata":{"id":"2qpjVC_1hoqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","if text_block:\n","    translated = translator.translate(text_block.strip(), dest=target_language).text\n","    translated_lines.append(text_block.strip())\n","    translated_lines.append(translated + \"\\n\")\n","\n","# Write translated subtitles to a new file\n","translated_subtitle_file = 'translated_subtitles.srt'\n","with open(translated_subtitle_file, 'w', encoding='utf-8') as file:\n","    for line in translated_lines:\n","        file.write(line + '\\n')\n"],"metadata":{"id":"qzZ3WR7zht4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soft_subtitle = False  # Set to True for soft subtitles, False for hard subtitles\n","\n","add_subtitle_to_video(soft_subtitle, translated_subtitle_file, subtitle_language, input_video, input_video_name)\n"],"metadata":{"id":"bAQa9D7IhvlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jdln6msWOSiL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CiIj5bUUQKdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qt03PGyAQKbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Vvo8wqgqPOL","executionInfo":{"status":"ok","timestamp":1716391710541,"user_tz":-180,"elapsed":10,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"aab0592b-d6f7-43eb-b621-6b24ca7520ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import load_model\n","loaded_model = load_model('sentiment_classification_based_on_text.h5')"],"metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:44:29.286825Z","iopub.execute_input":"2024-05-20T10:44:29.287203Z","iopub.status.idle":"2024-05-20T10:44:29.542482Z","shell.execute_reply.started":"2024-05-20T10:44:29.287171Z","shell.execute_reply":"2024-05-20T10:44:29.541212Z"},"trusted":true,"id":"mx3LQYv7qPOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Example compilation\n"],"metadata":{"id":"OaMqU_E3qPOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a dictionary of chat word mappings\n","chat_words = {\n","    \"AFAIK\": \"As Far As I Know\",\n","    \"AFK\": \"Away From Keyboard\",\n","    \"ASAP\": \"As Soon As Possible\",\n","    \"ATK\": \"At The Keyboard\",\n","    \"ATM\": \"At The Moment\",\n","    \"A3\": \"Anytime, Anywhere, Anyplace\",\n","    \"BAK\": \"Back At Keyboard\",\n","    \"BBL\": \"Be Back Later\",\n","    \"BBS\": \"Be Back Soon\",\n","    \"BFN\": \"Bye For Now\",\n","    \"B4N\": \"Bye For Now\",\n","    \"BRB\": \"Be Right Back\",\n","    \"BRT\": \"Be Right There\",\n","    \"BTW\": \"By The Way\",\n","    \"B4\": \"Before\",\n","    \"B4N\": \"Bye For Now\",\n","    \"CU\": \"See You\",\n","    \"CUL8R\": \"See You Later\",\n","    \"CYA\": \"See You\",\n","    \"FAQ\": \"Frequently Asked Questions\",\n","    \"FC\": \"Fingers Crossed\",\n","    \"FWIW\": \"For What It's Worth\",\n","    \"FYI\": \"For Your Information\",\n","    \"GAL\": \"Get A Life\",\n","    \"GG\": \"Good Game\",\n","    \"GN\": \"Good Night\",\n","    \"GMTA\": \"Great Minds Think Alike\",\n","    \"GR8\": \"Great!\",\n","    \"G9\": \"Genius\",\n","    \"IC\": \"I See\",\n","    \"ICQ\": \"I Seek you (also a chat program)\",\n","    \"ILU\": \"ILU: I Love You\",\n","    \"IMHO\": \"In My Honest/Humble Opinion\",\n","    \"IMO\": \"In My Opinion\",\n","    \"IOW\": \"In Other Words\",\n","    \"IRL\": \"In Real Life\",\n","    \"KISS\": \"Keep It Simple, Stupid\",\n","    \"LDR\": \"Long Distance Relationship\",\n","    \"LMAO\": \"Laugh My A.. Off\",\n","    \"LOL\": \"Laughing Out Loud\",\n","    \"LTNS\": \"Long Time No See\",\n","    \"L8R\": \"Later\",\n","    \"MTE\": \"My Thoughts Exactly\",\n","    \"M8\": \"Mate\",\n","    \"NRN\": \"No Reply Necessary\",\n","    \"OIC\": \"Oh I See\",\n","    \"PITA\": \"Pain In The A..\",\n","    \"PRT\": \"Party\",\n","    \"PRW\": \"Parents Are Watching\",\n","    \"QPSA?\": \"Que Pasa?\",\n","    \"ROFL\": \"Rolling On The Floor Laughing\",\n","    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n","    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n","    \"SK8\": \"Skate\",\n","    \"STATS\": \"Your sex and age\",\n","    \"ASL\": \"Age, Sex, Location\",\n","    \"THX\": \"Thank You\",\n","    \"TTFN\": \"Ta-Ta For Now!\",\n","    \"TTYL\": \"Talk To You Later\",\n","    \"U\": \"You\",\n","    \"U2\": \"You Too\",\n","    \"U4E\": \"Yours For Ever\",\n","    \"WB\": \"Welcome Back\",\n","    \"WTF\": \"What The F...\",\n","    \"WTG\": \"Way To Go!\",\n","    \"WUF\": \"Where Are You From?\",\n","    \"W8\": \"Wait...\",\n","    \"7K\": \"Sick:-D Laugher\",\n","    \"TFW\": \"That feeling when\",\n","    \"MFW\": \"My face when\",\n","    \"MRW\": \"My reaction when\",\n","    \"IFYP\": \"I feel your pain\",\n","    \"TNTL\": \"Trying not to laugh\",\n","    \"JK\": \"Just kidding\",\n","    \"IDC\": \"I don't care\",\n","    \"ILY\": \"I love you\",\n","    \"IMU\": \"I miss you\",\n","    \"ADIH\": \"Another day in hell\",\n","    \"ZZZ\": \"Sleeping, bored, tired\",\n","    \"WYWH\": \"Wish you were here\",\n","    \"TIME\": \"Tears in my eyes\",\n","    \"BAE\": \"Before anyone else\",\n","    \"FIMH\": \"Forever in my heart\",\n","    \"BSAAW\": \"Big smile and a wink\",\n","    \"BWL\": \"Bursting with laughter\",\n","    \"BFF\": \"Best friends forever\",\n","    \"CSL\": \"Can't stop laughing\"\n","}"],"metadata":{"id":"PnwM8-Be2b-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a mapping dictionary\n","label_mapping = {'surprise':0, 'worry':1, 'hate':2, 'happiness':3, 'sadness':4, 'anger':5, 'neutral':6}"],"metadata":{"id":"EVmrok4GPSsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Open the file for reading\n","with open(\"/content/drive/MyDrive/NLP_Project/sentences_video03.txt\", \"r\") as text_file:\n","  # Create an empty list to store the lines\n","  test = []\n","  # Read each line from the file\n","  for line in text_file:\n","    # Remove any trailing newline character\n","    line = line.strip()\n","    # Add the line to the new array\n","    test.append(line)"],"metadata":{"id":"cf7m5AUgisf0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPQQH9yZiscY","executionInfo":{"status":"ok","timestamp":1716391712496,"user_tz":-180,"elapsed":75,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"c058374f-a00c-48d3-c75a-5123ffe34856"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hey, this is Ken from AES.',\n"," \"Sometimes we're asked about the difference between what we do and a textbook.\",\n"," \"Let's talk about textbooks first.\",\n"," 'The best thing about a textbook is you can buy it once and you can keep using it for three or four years.']"]},"metadata":{},"execution_count":206}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","import re\n","from nltk.corpus import stopwords\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import pickle\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vq4i53EL8e6J","executionInfo":{"status":"ok","timestamp":1716391712496,"user_tz":-180,"elapsed":65,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"8d5db18d-686a-4977-ecd8-5332b6f571ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":207}]},{"cell_type":"code","source":["\n","\n","def preprocess_text(text):\n","\n","    words = text.split()\n","    for i, word in enumerate(words):\n","        if word.lower() in [word.lower() for word in list(chat_words.keys())]:\n","            words[i] = chat_words[word]\n","    text = ' '.join(words)\n","\n","    # Remove non-alphabetic and non-space characters\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    # Remove stopwords\n","    stop = stopwords.words('english')\n","    text = ' '.join([word for word in text.split() if word not in stop])\n","\n","    # Convert to lowercase\n","    text = text.lower()\n","\n","    # Remove digits\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Remove extra whitespaces\n","    text = re.sub(r'\\s+', ' ', text)\n","\n","    # Remove non-alphanumeric characters\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","\n","    # Remove URLs\n","    text = re.sub(r'http\\S+', '', text)\n","\n","    # Initialize the PorterStemmer\n","    stemmer = PorterStemmer()\n","    # Function to apply stemming to a text\n","    words = word_tokenize(text)\n","    stemmed_words = [stemmer.stem(word) for word in words]\n","    text =  ' '.join(stemmed_words)\n","\n","\n","    return text\n","\n"],"metadata":{"id":"Wo5R5tpI2MVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = [preprocess_text(text) for text in test]"],"metadata":{"id":"a8VY8zDe2MSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WNoO-PR2MQM","executionInfo":{"status":"ok","timestamp":1716391712496,"user_tz":-180,"elapsed":58,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"779b0f13-c2cd-44ca-9035-2f9b0b6c2270"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hey ken ae',\n"," 'sometim ask differ textbook',\n"," 'let talk textbook first',\n"," 'the best thing textbook buy keep use three four year']"]},"metadata":{},"execution_count":210}]},{"cell_type":"code","source":["# Later, when you want to use the saved tokenizer:\n","# Load the tokenizer from the file\n","with open('/content/drive/MyDrive/NLP_Project/tokenizer.pkl', 'rb') as f:\n","    tokenizer = pickle.load(f)\n","\n","# Now you can use the loaded tokenizer to tokenize your text\n","tokenized_text = tokenizer.texts_to_sequences(test)"],"metadata":{"id":"v01E5qbOOY4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOwn-f7_OY1K","executionInfo":{"status":"ok","timestamp":1716391712497,"user_tz":-180,"elapsed":52,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"8c07a275-25f3-4289-bd5d-7b13b9b5d125"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1482, 6015, 17178],\n"," [88, 127, 236, 4725],\n"," [116, 86, 4725, 110],\n"," [37898, 235, 14, 4725, 611, 100, 46, 527, 1008, 43]]"]},"metadata":{},"execution_count":212}]},{"cell_type":"code","source":["test_sequence = tokenized_text"],"metadata":{"collapsed":true,"id":"myp8CVcb0QW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_padded = pad_sequences(test_sequence, maxlen=maxlen, padding='post')"],"metadata":{"id":"_tMY7Qyg_nAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predictions On Test For Confustion Matrix\n","y_pred = loaded_model.predict(test_padded)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpDM9UNfk2la","executionInfo":{"status":"ok","timestamp":1716391713050,"user_tz":-180,"elapsed":599,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"9bd93dbd-f88f-4c79-b72c-e2baf481cc5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 670ms/step\n","[[9.30251427e-13 1.30294115e-14 5.33976960e-11 1.08259313e-11\n","  4.80390424e-12 3.02956336e-13 1.00000000e+00]\n"," [1.76779850e-18 2.39250845e-20 2.18692492e-17 9.56213426e-18\n","  5.25495535e-16 3.04875914e-15 1.00000000e+00]\n"," [3.10017262e-16 9.65066451e-19 1.74370986e-15 9.63119761e-14\n","  6.79040916e-13 1.08939897e-12 1.00000000e+00]\n"," [2.95494966e-21 7.75759200e-22 2.70916767e-18 4.81240032e-18\n","  2.67075259e-16 9.00005197e-17 1.00000000e+00]]\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.nn import functional as F  # Import functional for softmax\n","\n","\n","# Create a PyTorch tensor\n","tensor = torch.tensor(y_pred)\n","\n","# Apply softmax along the specified dimension (default is dim=1)\n","softmax_output = F.softmax(tensor, dim=1)\n","\n","print(softmax_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KpL-PoLyaY1","executionInfo":{"status":"ok","timestamp":1716391713050,"user_tz":-180,"elapsed":42,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"6ea3d3b2-685e-4156-ad0d-c58c8241b41d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118]])\n"]}]},{"cell_type":"code","source":["\n","# Convert softmax_output tensor to numpy array\n","softmax_array = softmax_output.cpu().detach().numpy()\n"],"metadata":{"id":"4_paZkenQbae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project"],"metadata":{"executionInfo":{"status":"ok","timestamp":1716391713050,"user_tz":-180,"elapsed":36,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"ae18e418-736e-40dc-c317-6d38b6bb20ed","colab":{"base_uri":"https://localhost:8080/"},"id":"ZiDfaDaIQbaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["\n","# Save the softmax arrays to a text file\n","with open(\"softmax_output_of_text.txt\", \"w\") as file:\n","    for array in softmax_array:\n","        file.write(' '.join([str(elem) for elem in array]) + '\\n')"],"metadata":{"id":"BrwJUMABQbaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","y_pred = np.argmax(y_pred, axis=1)\n","y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDqdxGezqPOL","executionInfo":{"status":"ok","timestamp":1716391713051,"user_tz":-180,"elapsed":31,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"a054822a-fc5b-4fe7-d6f2-e149e330c11d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([6, 6, 6, 6])"]},"metadata":{},"execution_count":221}]},{"cell_type":"code","source":["def get_key_from_value(dictionary, value):\n","    for key, val in dictionary.items():\n","        if val == value:\n","            return key\n","    return None  # If the value is not found"],"metadata":{"id":"JwhS8-0WUUi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = [get_key_from_value(label_mapping, label) for label in y_pred]\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oB8BG7NUUf_","executionInfo":{"status":"ok","timestamp":1716391713051,"user_tz":-180,"elapsed":24,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"226902fc-db3a-4d54-cf3a-4fb25281b1e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Nneutral', 'Nneutral', 'Nneutral', 'Nneutral']"]},"metadata":{},"execution_count":223}]},{"cell_type":"code","source":[],"metadata":{"id":"ApQgZn48QKX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7HHRCz17OSfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gVS9lz0qOSct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Hxue4Ic-Na0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezSYMg3xz7Sl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716376065280,"user_tz":-180,"elapsed":347,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"aec526dc-a87e-4497-d714-62be8af98bc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SentimentalAnalyze/POSTER_AND_LDLVA/POSTER\n"]}],"source":["%cd /content/drive/MyDrive/SentimentalAnalyze/POSTER_AND_LDLVA/POSTER"]},{"cell_type":"code","source":["!pip install -r req.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-N1uvvY-0r2_","executionInfo":{"status":"ok","timestamp":1716376071579,"user_tz":-180,"elapsed":6303,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"534ddeec-82db-4d73-d1b8-7d827fc6649f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r req.txt (line 1)) (4.8.0.76)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r req.txt (line 2)) (2.0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r req.txt (line 3)) (1.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r req.txt (line 4)) (3.7.1)\n","Collecting einops (from -r req.txt (line 5))\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python->-r req.txt (line 1)) (1.25.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r req.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r req.txt (line 2)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r req.txt (line 2)) (2024.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r req.txt (line 3)) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r req.txt (line 3)) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r req.txt (line 3)) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r req.txt (line 4)) (3.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r req.txt (line 2)) (1.16.0)\n","Installing collected packages: einops\n","Successfully installed einops-0.8.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQDIo9e4z7Sn"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import torch.utils.data as data\n","from torchvision import transforms\n","import torch\n","import os\n","import argparse\n","from data_preprocessing.dataset_raf import RafDataSet\n","from data_preprocessing.dataset_affectnet import Affectdataset\n","from data_preprocessing.dataset_affectnet_8class import Affectdataset_8class\n","import random\n","\n","from utils import *\n","from models.emotion_hyp import pyramid_trans_expr\n","from sklearn.metrics import confusion_matrix\n","from data_preprocessing.plot_confusion_matrix import plot_confusion_matrix\n","\n","import cv2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVMy-bUUz7Sn","outputId":"3b6cca76-b785-439b-891d-5b5137302b6d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716373695973,"user_tz":-180,"elapsed":12,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Work on GPU:  0,1\n"]}],"source":["os.environ['CUDA_VISIBLE_DEVICES'] = str('0,1')\n","print(\"Work on GPU: \", os.environ['CUDA_VISIBLE_DEVICES'])"]},{"cell_type":"code","source":["\n","def save_random_frame_from_section(video_path, output_folder, section_start, section_end, section_number):\n","    cap = cv2.VideoCapture(video_path)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    start_frame = int(section_start * fps)\n","    end_frame = int(section_end * fps)\n","\n","    random_frame = random.randint(start_frame, end_frame)\n","    cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame)\n","\n","    ret, frame = cap.read()\n","    if ret:\n","        frame_filename = os.path.join(output_folder, f\"frame_section_{section_number}.jpg\")\n","        cv2.imwrite(frame_filename, frame)\n","        print(f\"Saved frame from section {section_number} to {frame_filename}\")\n","    else:\n","        print(f\"Failed to capture frame from section {section_number}\")\n","\n","    cap.release()"],"metadata":{"id":"rcPjBKlo35Uq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_frames(video_path, output_folder, num_sections=1):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    duration = total_frames / fps\n","\n","    section_duration = duration / 4\n","\n","    sections_to_extract = random.sample(range(1, 5), min(num_sections, 4))\n","\n","    for section_number in sections_to_extract:\n","        section_start = (section_number - 1) * section_duration\n","        section_end = section_number * section_duration\n","        save_random_frame_from_section(video_path, output_folder, section_start, section_end, section_number)\n","\n","    cap.release()"],"metadata":{"id":"GMRZ_zYO3-zY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","num_sections = sentences_num"],"metadata":{"id":"JEh3LTvN4ycK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_frames(video_path, output_folder, num_sections)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2MRf48T4JJB","executionInfo":{"status":"ok","timestamp":1716374885312,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"ba67a37c-18c2-4656-a076-62e92e3d6275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved frame from section 1 to /content/drive/MyDrive/NLP_Project/Photos_to_predict/frame_section_1.jpg\n","Saved frame from section 2 to /content/drive/MyDrive/NLP_Project/Photos_to_predict/frame_section_2.jpg\n","Saved frame from section 3 to /content/drive/MyDrive/NLP_Project/Photos_to_predict/frame_section_3.jpg\n","Saved frame from section 4 to /content/drive/MyDrive/NLP_Project/Photos_to_predict/frame_section_4.jpg\n"]}]},{"cell_type":"code","source":["def read_images_from_folder(folder_path):\n","    images = []\n","    for filename in os.listdir(folder_path):\n","        img_path = os.path.join(folder_path, filename)\n","        if os.path.isfile(img_path):\n","            # Read the image\n","            img = cv2.imread(img_path)\n","            if img is not None:\n","                images.append(img)\n","            else:\n","                print(f\"Could not read image: {img_path}\")\n","    return images\n","\n","images_array = read_images_from_folder(output_folder)\n","\n","# Now you have all the images stored in the `images_array` list"],"metadata":{"id":"XuLNnN6L3xH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSZv4Stp-A86"},"outputs":[],"source":["transform = transforms.Compose([\n","        transforms.ToPILImage(),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"42871e61-3054-4297-8b13-b71dec73a3b7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716376121877,"user_tz":-180,"elapsed":16933,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"id":"r0BQotxZ-A86"},"outputs":[{"output_type":"stream","name":"stdout","text":["load_weight 304\n"]}],"source":["model = pyramid_trans_expr(img_size=224, num_classes=num_classes, type=\"large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTpSQmnZ-A87"},"outputs":[],"source":["def add_gaussian_noise(image_array, mean=0.0, var=30):\n","    std = var**0.5\n","    noisy_img = image_array + np.random.normal(mean, std, image_array.shape)\n","    noisy_img_clipped = np.clip(noisy_img, 0, 255).astype(np.uint8)\n","    return noisy_img_clipped\n","\n","def flip_image(image_array):\n","    return cv2.flip(image_array, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0DJQTQ7J-A87"},"outputs":[],"source":["aug_func = [flip_image, add_gaussian_noise]"]},{"cell_type":"code","source":["index = 0\n","for img in images_array:\n","  i = random.randint(0, 1)\n","  img = aug_func[i](img)\n","  img = transform(img.copy())\n","  images_array[index] = img\n","  index += 1"],"metadata":{"id":"dkUJLeYf3xEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader = torch.utils.data.DataLoader(images_array,\n","                                             batch_size=32,\n","                                             num_workers=2,\n","                                             shuffle=False,\n","                                             pin_memory=True)"],"metadata":{"id":"9advhCHP7vO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"5a4cc1ed-b660-43cc-c145-0cabac90b9bb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716376136912,"user_tz":-180,"elapsed":10770,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"id":"7h5WOAxM92pS"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pretrained weights... /content/drive/MyDrive/SentimentalAnalyze/POSTER_AND_LDLVA/POSTER/checkpoint/rafdb_best.pth\n","load_weight 1309\n"]}],"source":["print(\"Loading pretrained weights...\", \"/content/drive/MyDrive/SentimentalAnalyze/POSTER_AND_LDLVA/POSTER/checkpoint/rafdb_best.pth\")\n","checkpoint = torch.load(\"/content/drive/MyDrive/SentimentalAnalyze/POSTER_AND_LDLVA/POSTER/checkpoint/rafdb_best.pth\")\n","checkpoint = checkpoint[\"model_state_dict\"]\n","model = load_pretrained_weights(model, checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jv-YgC9o92pf"},"outputs":[],"source":["model = model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mc-SL57392pg","executionInfo":{"status":"ok","timestamp":1716376146008,"user_tz":-180,"elapsed":2642,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"b23a2e4e-99b0-4a86-ad43-7cd4de968269"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3, 2, 2, 0], device='cuda:0')\n","tensor([[-0.4358, -1.0675,  0.3217,  2.8434, -0.8518, -0.3195, -0.4349],\n","        [ 0.2487, -1.2416,  1.9898,  0.5242, -0.4681,  0.1476, -0.6603],\n","        [ 0.9859, -1.3570,  1.5785,  0.0784, -0.4941,  0.0539, -0.7567],\n","        [ 1.3812, -1.3101,  1.2315, -0.0459, -0.3129,  0.3867, -1.1606]],\n","       device='cuda:0')\n"]}],"source":["with torch.no_grad():\n","    bingo_cnt = 0\n","    model.eval()\n","    for batch_i, (imgs) in enumerate(test_loader):\n","        outputs, features = model(imgs.cuda())\n","        _, predicts = torch.max(outputs, 1)\n","        print(predicts)\n","        print(outputs)"]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n"],"metadata":{"id":"z5gjEX21_agZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply softmax along the specified dimension (default is dim=1)\n","softmax_output = F.softmax(outputs, dim=1)\n","softmax_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R74be0OwAZIF","executionInfo":{"status":"ok","timestamp":1716376421262,"user_tz":-180,"elapsed":330,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"6d786254-4cb3-41ef-fcf6-c8704b4f54ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0303, 0.0161, 0.0646, 0.8046, 0.0200, 0.0340, 0.0303],\n","        [0.0996, 0.0224, 0.5680, 0.1312, 0.0486, 0.0900, 0.0401],\n","        [0.2436, 0.0234, 0.4406, 0.0983, 0.0555, 0.0959, 0.0426],\n","        [0.3570, 0.0242, 0.3074, 0.0857, 0.0656, 0.1321, 0.0281]],\n","       device='cuda:0')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["\n","# Convert softmax_output tensor to numpy array\n","softmax_array = softmax_output.cpu().detach().numpy()\n"],"metadata":{"id":"cJQ3M8OFAWUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project"],"metadata":{"id":"nGFY2NKSAmHm","executionInfo":{"status":"ok","timestamp":1716376473927,"user_tz":-180,"elapsed":6,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"e053e6b2-61a5-491f-e3b7-9604ff5b228f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["\n","# Save the softmax arrays to a text file\n","with open(\"softmax_output_of_video.txt\", \"w\") as file:\n","    for array in softmax_array:\n","        file.write(' '.join([str(elem) for elem in array]) + '\\n')"],"metadata":{"id":"-XfGlad8_0hQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oP6DL5ZpP4OJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nrASdTM2SJ10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"grpBzfl8SJz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-z6OTo4GSJyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CY1bJiRjSJtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UC3R0m8WSJqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","def read_data(filename):\n","  \"\"\"Reads data from a file into a PyTorch tensor.\"\"\"\n","  with open(filename, 'r') as f:\n","    data_lines = f.readlines()  # Read all lines\n","\n","  data = []\n","  for line in data_lines:\n","    data.append([float(x) for x in line.strip().split()])  # Split and convert each line\n","\n","  return torch.tensor(data)  # Create a 2D tensor\n","\n","def element_wise_dot_product(file1, file2):\n","  \"\"\"Reads data from files, performs element-wise dot product, and applies softmax.\"\"\"\n","  data1 = read_data(file1)\n","  data2 = read_data(file2)\n","  print(data1)\n","  print(data2)\n","  # Ensure data has the same dimensions\n","  if data1.size() != data2.size():\n","    raise ValueError(\"Data in files must have the same dimensions for element-wise multiplication.\")\n","\n","  # Calculate element-wise dot product\n","  element_wise_product = data1 * data2  # Use element-wise multiplication operator\n","  print(element_wise_product)\n","  # Apply softmax on each row (assuming data points are in rows)\n","  softmax = torch.nn.functional.softmax(element_wise_product, dim=1)\n","\n","  return softmax\n","\n","\n","# Example usage (replace 'file1.txt' and 'file2.txt' with your actual file paths)\n","result = element_wise_dot_product(softmax_of_text, softmax_of_video)\n","print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77azSLanrV6B","executionInfo":{"status":"ok","timestamp":1716409193590,"user_tz":-180,"elapsed":2008,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"6ac4597c-7cea-4dc3-9085-b3b7a828a2d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118],\n","        [0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118]])\n","tensor([[0.0303, 0.0161, 0.0646, 0.8046, 0.0200, 0.0340, 0.0303],\n","        [0.0996, 0.0224, 0.5680, 0.1312, 0.0486, 0.0900, 0.0401],\n","        [0.2436, 0.0234, 0.4406, 0.0983, 0.0555, 0.0959, 0.0426],\n","        [0.3570, 0.0242, 0.3074, 0.0857, 0.0656, 0.1321, 0.0281]])\n","tensor([[0.0035, 0.0018, 0.0074, 0.0923, 0.0023, 0.0039, 0.0095],\n","        [0.0114, 0.0026, 0.0652, 0.0150, 0.0056, 0.0103, 0.0125],\n","        [0.0279, 0.0027, 0.0505, 0.0113, 0.0064, 0.0110, 0.0133],\n","        [0.0409, 0.0028, 0.0353, 0.0098, 0.0075, 0.0151, 0.0088]])\n","tensor([[0.1408, 0.1406, 0.1414, 0.1539, 0.1407, 0.1409, 0.1417],\n","        [0.1420, 0.1407, 0.1498, 0.1425, 0.1411, 0.1418, 0.1421],\n","        [0.1443, 0.1407, 0.1476, 0.1419, 0.1412, 0.1419, 0.1422],\n","        [0.1463, 0.1408, 0.1454, 0.1418, 0.1415, 0.1426, 0.1416]])\n"]}]},{"cell_type":"code","source":["result_np = result.numpy()"],"metadata":{"id":"XLwGJT0s173v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project\n","# Save the softmax arrays to a text file\n","with open(\"softmax_result.txt\", \"w\") as file:\n","    for array in result_np:\n","        file.write(' '.join([str(elem) for elem in array]) + '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlCQJtX7zkbO","executionInfo":{"status":"ok","timestamp":1716409193591,"user_tz":-180,"elapsed":14,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"befde972-d3ab-4659-a480-b592a35ff5ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["import numpy as np\n","final_result = np.argmax(result, axis=1)\n","final_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_la5W2MW4vl9","executionInfo":{"status":"ok","timestamp":1716409194532,"user_tz":-180,"elapsed":10,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"c89e3062-95f9-419d-abb8-cddb2b9302ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 2, 2, 0])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Define a mapping dictionary\n","label_mapping = {'surprise':0, 'worry':1, 'hate':2, 'happiness':3, 'sadness':4, 'anger':5, 'neutral':6}"],"metadata":{"id":"mrlcyha32RPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_key_from_value(dictionary, value):\n","    for key, val in dictionary.items():\n","        if val == value:\n","            return key\n","    return None  # If the value is not found"],"metadata":{"id":"wtyYU24T0wU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = [get_key_from_value(label_mapping, label) for label in final_result]\n","res"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ctx8ygXx2Jm4","executionInfo":{"status":"ok","timestamp":1716409205666,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"1b7f4550-b5d9-4ddc-b9a3-e03a526217ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['happiness', 'hate', 'hate', 'surprise']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NLP_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBp5o_yp-iAu","executionInfo":{"status":"ok","timestamp":1716410356424,"user_tz":-180,"elapsed":793,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"31906b6b-d983-4b31-b11b-7b1ee28438c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Project\n"]}]},{"cell_type":"code","source":["!pip install opencv-python-headless moviepy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbjKLYKP_nxx","executionInfo":{"status":"ok","timestamp":1716409771230,"user_tz":-180,"elapsed":6135,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"69d244fa-642c-4d79-be58-14cf3e8a7970"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n"]}]},{"cell_type":"code","source":["import cv2\n","from moviepy.editor import VideoFileClip, AudioFileClip\n","\n","# Define your list of texts\n","text_list = res\n","input_video = input_video_to_add_sentiment  # Get the uploaded video filename\n","output_video_with_audio = \"output_video_with_audio.mp4\"\n","\n","# Open the video file with OpenCV\n","cap = cv2.VideoCapture(input_video)\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","duration = frame_count / fps\n","\n","# Calculate the duration each text should be displayed\n","num_texts = len(text_list)\n","display_duration = duration / num_texts\n","frames_per_text = int(display_duration * fps)\n","\n","# Get video properties\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Define the codec and create a temporary VideoWriter object\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","temp_output = \"temp_output.mp4\"\n","out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))\n","\n","current_text_index = 0\n","frame_index = 0\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Calculate which text to display based on frame index\n","    current_text_index = frame_index // frames_per_text\n","    if current_text_index >= num_texts:\n","        current_text_index = num_texts - 1\n","\n","    text = \"Sentiment: \" + text_list[current_text_index]\n","\n","    # Put the text on the frame\n","    cv2.putText(frame, text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3, cv2.LINE_AA)\n","\n","    # Write the frame to the output video\n","    out.write(frame)\n","\n","    frame_index += 1\n","\n","# Release everything if job is finished\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","# Use moviepy to add the original audio back to the processed video\n","original_video = VideoFileClip(input_video)\n","processed_video = VideoFileClip(temp_output)\n","\n","final_video = processed_video.set_audio(original_video.audio)\n","final_video.write_videofile(output_video_with_audio, codec=\"libx264\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_cXo8HQ_r3V","executionInfo":{"status":"ok","timestamp":1716410375000,"user_tz":-180,"elapsed":4393,"user":{"displayName":"Ahmed TABŞO","userId":"08104695456374651508"}},"outputId":"a2479e08-13a8-4889-9278-5d4e008becea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video output_video_with_audio.mp4.\n","MoviePy - Writing audio in output_video_with_audioTEMP_MPY_wvf_snd.mp3\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video output_video_with_audio.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready output_video_with_audio.mp4\n"]}]}]}